# Endpoint: bi-airflow-dev
# Stack: airflow-development
version: '3.8'
services:
  datawarehouse:
    image: postgres:16
    deploy:
      placement:
        constraints: [node.role == manager]
    environment:
      - PGDATA=/var/lib/postgresql/data
      - POSTGRES_DB=datawarehouse
      - POSTGRES_HOST=datawarehouse
      - POSTGRES_PASSWORD=<PASSWORD>
      - POSTGRES_PORT=5432
      - POSTGRES_USER=postgres
    volumes:
      - ~/projects/pipeline/airflow/dwdata:/var/lib/postgresql/data
    networks:
      - airflow_network
      # - datadog-network
    ports:
      - 5433:5432
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
  postgres:
    image: postgres:16
    deploy:
      placement:
        constraints: [node.role == manager]
    environment:
      - PGDATA=/var/lib/postgresql/data
      - POSTGRES_DB=airflow
      - POSTGRES_HOST=postgres
      - POSTGRES_PASSWORD=<PASSWORD>
      - POSTGRES_PORT=5432
      - POSTGRES_USER=airflow
    volumes:
      - ~/projects/pipeline/airflow/pgdata:/var/lib/postgresql/data
    networks:
      - airflow_network
      # - datadog-network
    ports:
      - 5432:5432
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5

  redis:
    image: redis:latest
    command: redis-server --requirepass <PASSWORD>
    networks:
      - airflow_network
      # - datadog-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 30s
      retries: 50

  webserver:
    image: custom-airflow:V1
    deploy:
      placement:
        constraints: [node.role == manager]
    command: webserver
    ports:
      - "8080:8080"
    environment:
      - _AIRFLOW_DB_UPGRADE=true
      - _AIRFLOW_WWW_USER_CREATE=true
      - _AIRFLOW_WWW_USER_PASSWORD=<PASSWORD>
      - AIRFLOW_UID=501
      - POSTGRES_PASSWORD=<PASSWORD>

    volumes:
      - ~/projects/pipeline/airflow/dags:/opt/airflow/dags
      - ~/projects/pipeline/airflow/logs:/opt/airflow/logs
      - ~/projects/pipeline/airflow/plugins:/opt/airflow/plugins
      - ~/projects/pipeline/airflow/conf/airflow.cfg:/opt/airflow/airflow.cfg
    networks:
      - airflow_network

  scheduler:
    image: custom-airflow:V1
    deploy:
      placement:
        constraints: [node.role == manager]
    command: scheduler
    environment:
      - _AIRFLOW_DB_UPGRADE=true
    volumes:
      - ~/projects/pipeline/airflow/dags:/opt/airflow/dags
      - ~/projects/pipeline/airflow/logs:/opt/airflow/logs
      - ~/projects/pipeline/airflow/plugins:/opt/airflow/plugins
      - ~/projects/pipeline/airflow/conf/airflow.cfg:/opt/airflow/airflow.cfg
    networks:
      - airflow_network

  worker:
    image: custom-airflow:V1
    deploy:
      placement:
        constraints: [node.role == manager]
    command: celery worker
    environment:
      - _AIRFLOW_DB_UPGRADE=true
      - POSTGRES_PASSWORD=<PASSWORD>
    volumes:
      - ~/projects/pipeline/airflow/dags:/opt/airflow/dags
      - ~/projects/pipeline/airflow/logs:/opt/airflow/logs
      - ~/projects/pipeline/airflow/plugins:/opt/airflow/plugins
      - ~/projects/pipeline/airflow/conf/airflow.cfg:/opt/airflow/airflow.cfg
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - airflow_network

  flower:
    image: custom-airflow:V1
    deploy:
      placement:
        constraints: [node.role == manager]
    entrypoint: ./entrypoint.sh airflow flower --basic_auth ${AIRFLOW__FLOWER__AUTH}
    command: celery flower
    environment:
      - _AIRFLOW_DB_UPGRADE=true
    volumes:
      - ~/projects/pipeline/airflow/dags:/opt/airflow/dags
      - ~/projects/pipeline/airflow/logs:/opt/airflow/logs
      - ~/projects/pipeline/airflow/plugins:/opt/airflow/plugins
      - ~/projects/pipeline/airflow/conf/airflow.cfg:/opt/airflow/airflow.cfg
    networks:
      - airflow_network
    ports:
      - 5555:5555
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5555/"]
      interval: 10s
      timeout: 10s
      retries: 5
  
  metabase:
    image: metabase/metabase:latest
    deploy:
      placement:
        constraints: [node.role == manager]
    environment:
      - MB_DB_TYPE=postgres
      - MB_DB_DBNAME=metabase
      - MB_DB_PORT=5444
      - MB_DB_USER=metabase
      - MB_DB_PASS=Abcd1234
      - MB_DB_HOST=localhost
      - MB_EMOJI_IN_LOGS=true
    volumes:
      - ~/projects/pipeline/metabase/metabase-data:/metabase-data
    networks:
      - airflow_network
    ports:
      - 3000:3000
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:3000/"]
      interval: 10s
      timeout: 10s
      retries: 5


networks:
  airflow_network:
    external: false


